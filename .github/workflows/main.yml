name: CERN Data Analysis Pipeline

# Este workflow se ejecuta cuando se hace push al branch 'main' o 'master'
on:
  push:
    branches:
      - main
      - master
  workflow_dispatch:

jobs:
  analyze_and_deploy:
    runs-on: ubuntu-latest
    
    # Define la clave para el cach√© de datos
    env:
      CACHE_KEY: cern-opendata-root-v1

    steps:
      - name: 1. Checkout Repository
        uses: actions/checkout@v4
        with:
          token: ${{ secrets.GITHUB_TOKEN }}
          
      - name: 2. Set up Python Environment
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: 3. Install Python Dependencies
        run: |
          pip install -r requirements.txt
          
      - name: 4. Restore/Download Data Cache (The Key Step!) üíæ
        uses: actions/cache@v4
        id: cache-data
        with:
          path: data
          key: ${{ runner.os }}-${{ env.CACHE_KEY }}

      - name: 5. Execute Data Analysis (Python)
        run: |
          echo "Starting analysis. This will download files only on first run."
          python analysis.py
          
      - name: 6. Prepare Results (Artifacts)
        # Renombramos la carpeta 'results' a 'docs' para GitHub Pages
        run: |
           cp -r results/* docs/ 
          
      - name: 7. Upload Results as Artifact ‚¨ÜÔ∏è
        uses: actions/upload-artifact@v4
        with:
          name: analysis-results
          path: docs/

      - name: 8. Deploy to GitHub Pages
        # Solo despliega si estamos en la rama principal (main o master)
        if: ${{ github.ref == 'refs/heads/main' || github.ref == 'refs/heads/master' }}
        uses: peaceiris/actions-gh-pages@v3
        with:
          github_token: ${{ secrets.GITHUB_TOKEN }}
          publish_dir: docs
      - name: 9. Final Setup for GitHub Pages Service
        run: echo "REMINDER: Set GitHub Pages source to 'gh-pages' or 'docs' folder."
